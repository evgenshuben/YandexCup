{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c137e16f-acc2-46bc-b6e9-b8aa5912963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63ed26b-40ed-467c-9f61-86aa6cab7f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_reduce_func(D_chunk, start, top_size=500):\n",
    "    # Находим индексы ближайших соседей\n",
    "    nearest_items = np.argsort(D_chunk, axis=1)[:, :top_size + 1]\n",
    "    \n",
    "    # Извлекаем соответствующие косинусные расстояния\n",
    "    nearest_distances = np.take_along_axis(D_chunk, nearest_items, axis=1)\n",
    "    \n",
    "    # Возвращаем пары (индексы и близости)\n",
    "    return [\n",
    "        (i, items[items != i], 1 - nearest_distances[idx][items != i])  # 1 - расстояние для получения близости\n",
    "        for idx, (i, items) in enumerate(zip(range(start, start + D_chunk.shape[0]), nearest_items))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ebdc79-7fe3-4759-be6e-08356433faad",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_for_stack = []\n",
    "for chunk_result in tqdm(pairwise_distances_chunked(\n",
    "        embeddings, metric='cosine', reduce_func=score_reduce_func, working_memory=100\n",
    ")):\n",
    "    for query_indx, query_nearest_items, query_similarities in chunk_result:\n",
    "        # Добавляем результаты: (ID трека запроса, [ID соседей], [косинусные близости соседей])\n",
    "        predictions_for_stack.append(\n",
    "            (trackids[query_indx],\n",
    "             [trackids[nn_indx] for nn_indx in query_nearest_items],\n",
    "             query_similarities.tolist())  # Преобразуем близости в список\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c99f74c-a79a-4abb-9e7e-a1e6d4eaa97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {}\n",
    "\n",
    "# Проходимся по списку predictions и заполняем словарь\n",
    "for track_id, candidate_ids, similarities in predictions_for_stack:\n",
    "    # Создаем пары (candidate_id, similarity) и добавляем в словарь\n",
    "    result_dict[track_id] = list(zip(candidate_ids, similarities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705bed5c-e5fa-4448-910e-ff5ad83cb65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_result_dict_with_model_scores(embeds_df):\n",
    "    embeddings = embeds_df['embedding'].tolist()\n",
    "    trackids = embeds_df.index.tolist()\n",
    "    \n",
    "    predictions_for_stack = []\n",
    "    for chunk_result in tqdm(pairwise_distances_chunked(\n",
    "            embeddings, metric='cosine', reduce_func=score_reduce_func, working_memory=100\n",
    "    )):\n",
    "        for query_indx, query_nearest_items, query_similarities in chunk_result:\n",
    "            # Добавляем результаты: (ID трека запроса, [ID соседей], [косинусные близости соседей])\n",
    "            predictions_for_stack.append(\n",
    "                (trackids[query_indx],\n",
    "                 [trackids[nn_indx] for nn_indx in query_nearest_items],\n",
    "                 query_similarities.tolist())  # Преобразуем близости в список\n",
    "            )\n",
    "            \n",
    "    result_dict = {}\n",
    "    # Проходимся по списку predictions и заполняем словарь\n",
    "    for track_id, candidate_ids, similarities in predictions_for_stack:\n",
    "        # Создаем пары (candidate_id, similarity) и добавляем в словарь\n",
    "        result_dict[track_id] = list(zip(candidate_ids, similarities))\n",
    "    \n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898bcb07-4e42-4cb8-b8d9-192b86d7995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = create_result_dict_with_model_scores(emb_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b2e938-20d4-4f21-88eb-523b444576f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a59500-9d89-4e68-b3ed-7df179eb543d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16877d7b-d788-459e-a330-1c2b72353b09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b158b86d-9272-49db-8fb2-9f21bf360436",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212246f4-be7e-4b5c-a485-de18fb32e3d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca331b2-6f19-425c-a749-f689fe782b27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd41de4c-51f0-40db-9345-a369141828b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f458a6-d8f0-4917-958c-d279f2f2e7dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2075a491-710c-4591-ac87-6c1443aec78a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2fc07c-23f3-4dbd-9165-38384b1b815f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "dl24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
