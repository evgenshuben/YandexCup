{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1325f054-563c-4359-a3b1-ff7c580efbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "PROJECT_DIR = '/home/evgenshuben/Desktop/gitReps/YandexCup/'\n",
    "sys.path.append(PROJECT_DIR)\n",
    "os.chdir(PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5d0a49a-f271-437b-91fd-a42e986e399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4facbd67-1cee-48e9-a245-8e2bc7d83262",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from scr.train import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8afdb7-2e3a-495d-baa5-af5b1b0575c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799fba9f-028e-43a6-951e-28b810c77f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62785237-c046-4894-a24d-ee2ba3e6af31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0a7aa44-91fd-4ef8-ab0d-55b923d97025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Путь к конфигурационному файлу, сохраненному Hydra\n",
    "config_path = \"/home/evgenshuben/Desktop/gitReps/YandexCup/outputs_val/run-3/hydra/.hydra/config.yaml\"\n",
    "\n",
    "\n",
    "\n",
    "cfg = OmegaConf.load(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080534e3-0e9f-43f7-9db1-40ae4b023955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7873ef09-04b8-4bba-a208-60232d43de95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evgenshuben/Desktop/gitReps/YandexCup/scr/train.py:50: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model.load_state_dict(torch.load(self.cfg.pipeline.model_ckpt), strict=False)\n",
      "/home/evgenshuben/miniconda3/envs/DL24/lib/python3.10/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at /opt/conda/conda-bld/pytorch_1728929546833/work/c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/gitReps/YandexCup/scr/train.py:39\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, cfg)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment_number \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mexperiment_number\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# needs for DL pipeline\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mearly_stop \u001b[38;5;241m=\u001b[39m EarlyStopper(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mpipeline\u001b[38;5;241m.\u001b[39mpatience) \u001b[38;5;66;03m# toDo Early stoper in hidra init\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m=\u001b[39m instantiate(cfg\u001b[38;5;241m.\u001b[39moptimizer, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters())\n",
      "File \u001b[0;32m~/Desktop/gitReps/YandexCup/scr/train.py:50\u001b[0m, in \u001b[0;36mTrainer._init_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m instantiate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mpipeline\u001b[38;5;241m.\u001b[39mmodel_ckpt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_ckpt\u001b[49m\u001b[43m)\u001b[49m, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     51\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel loaded from checkpoint: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mpipeline\u001b[38;5;241m.\u001b[39mmodel_ckpt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/miniconda3/envs/DL24/lib/python3.10/site-packages/torch/serialization.py:1360\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1358\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1359\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1360\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1361\u001b[0m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1362\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1363\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1364\u001b[0m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1365\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1366\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[1;32m   1368\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/DL24/lib/python3.10/site-packages/torch/serialization.py:1848\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[1;32m   1847\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m map_location\n\u001b[0;32m-> 1848\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1849\u001b[0m _serialization_tls\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1851\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n",
      "File \u001b[0;32m~/miniconda3/envs/DL24/lib/python3.10/site-packages/torch/serialization.py:1812\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1810\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1811\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1812\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1813\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1814\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1816\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m~/miniconda3/envs/DL24/lib/python3.10/site-packages/torch/serialization.py:1784\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1779\u001b[0m         storage\u001b[38;5;241m.\u001b[39mbyteswap(dtype)\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[0;32m-> 1784\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1785\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1786\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1787\u001b[0m )\n\u001b[1;32m   1789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1790\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
      "File \u001b[0;32m~/miniconda3/envs/DL24/lib/python3.10/site-packages/torch/serialization.py:601\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;124;03mRestores `storage` using a deserializer function registered for the `location`.\u001b[39;00m\n\u001b[1;32m    583\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;124;03m       all matching ones return `None`.\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 601\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    602\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    603\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/DL24/lib/python3.10/site-packages/torch/serialization.py:539\u001b[0m, in \u001b[0;36m_deserialize\u001b[0;34m(backend_name, obj, location)\u001b[0m\n\u001b[1;32m    537\u001b[0m     backend_name \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_privateuse1_backend_name()\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(backend_name):\n\u001b[0;32m--> 539\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/miniconda3/envs/DL24/lib/python3.10/site-packages/torch/serialization.py:508\u001b[0m, in \u001b[0;36m_validate_device\u001b[0;34m(location, backend_name)\u001b[0m\n\u001b[1;32m    506\u001b[0m     device_index \u001b[38;5;241m=\u001b[39m device\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;28;01mif\u001b[39;00m device\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_available\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m device_module\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m--> 508\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    509\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    510\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice but torch.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.is_available() is False. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    511\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    514\u001b[0m     )\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice_count\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    516\u001b[0m     device_count \u001b[38;5;241m=\u001b[39m device_module\u001b[38;5;241m.\u001b[39mdevice_count()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "trainer = Trainer(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e70d4f7-5555-4f3c-831c-3bde7244828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in trainer.train_dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356aaaa2-fb29-4285-9fe9-9a3664cc9385",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb601e3-08ba-4140-911c-a25b0d2efb8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dca79f0-0e84-4c12-9109-5d54ab15a157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7fd49ff0-35db-4819-aea7-53f4a64aefcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResCNNBlock1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, pool=True):\n",
    "        super(ResCNNBlock1d, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1, stride=1, bias=False)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3, padding=1, stride=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool1d(2) if pool else nn.Identity()\n",
    "\n",
    "        # Слой для проекции, если количество входных каналов не совпадает с выходными\n",
    "        self.shortcut = nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=1, padding=0) if in_channels != out_channels else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.shortcut(x)  # Применяем проекцию к входу\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        # Применяем пропускную связь\n",
    "        x += residual  # Добавляем вход к выходу блока\n",
    "        x = self.relu(x)  # Применяем активацию после добавления\n",
    "\n",
    "        x = self.maxpool(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "814024d6-18a1-4bcf-b1c7-a80034ab0ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet1d(nn.Module):\n",
    "    def __init__(self, emb_size=512, num_classes=8858, input_norm=False):\n",
    "        super(ResNet1d, self).__init__()\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm([84, 50]) if input_norm else nn.Identity()\n",
    "        self.block1 = ResCNNBlock1d(84, 64)\n",
    "        self.block2 = ResCNNBlock1d(64, 128)\n",
    "        self.block3 = ResCNNBlock1d(128, 256)\n",
    "        self.block4 = ResCNNBlock1d(256, 512)  # Добавлен новый блок для увеличения глубины\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc_emb = nn.Linear(512, emb_size)  # Увеличиваем вход для линейного слоя\n",
    "        self.fc = nn.Linear(emb_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_norm(x)\n",
    "        \n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)  # Новый блок\n",
    "\n",
    "        pooled_output = self.adaptive_pool(x)\n",
    "        pooled_output = pooled_output.view(pooled_output.size(0), -1)\n",
    "\n",
    "        emb = self.fc_emb(pooled_output)\n",
    "        cls = self.fc(emb)\n",
    "\n",
    "        return dict(emb=emb, cls=cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e43ff169-91ed-4f56-bd50-751fe7c06a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet1d(\n",
       "  (layer_norm): Identity()\n",
       "  (block1): ResCNNBlock1d(\n",
       "    (conv1): Conv1d(84, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (shortcut): Conv1d(84, 64, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (block2): ResCNNBlock1d(\n",
       "    (conv1): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (shortcut): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (block3): ResCNNBlock1d(\n",
       "    (conv1): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (shortcut): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (block4): ResCNNBlock1d(\n",
       "    (conv1): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (shortcut): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (adaptive_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (fc_emb): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc): Linear(in_features=512, out_features=8858, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet1d()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daeaadf-fa62-4174-87df-88b62b71aa90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a3956467-81ab-40dc-9f90-7799dd2ad590",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in trainer.train_dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "765f1964-efcb-46a7-8eda-be3b2d66ccbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 84, 50])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['anchor'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8962c974-485b-46b4-94ab-ce6472f5853d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 512])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(batch['anchor'])['emb'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b4529def-f357-4320-9ca7-c05254ba9b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5150d895-aaa4-429c-8e98-a4d9abdf59d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd3e568-bb6f-4d0c-bd85-cdadde2c17d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df687de0-33c4-4eda-80b3-29902bfec39c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd048130-a6ec-4c73-8049-aa9ae880ef8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c164866e-e10c-48c3-a788-e3147693e8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
